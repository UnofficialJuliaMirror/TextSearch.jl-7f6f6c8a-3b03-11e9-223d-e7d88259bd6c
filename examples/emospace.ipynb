{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting emojis for Spanish tweets\n",
    "Author: Eric S. Tellez -- [donsadit@gmail.com](mailto:donsadit@gmail.com)\n",
    "\n",
    "## Abstract\n",
    "This scripts shows how to create a text model and a classifier that predicts the related emoji for a given short text.\n",
    "The text model can be a classifical TFIDF model or an Entropy based weighting; we can reduce the size of the model using prunning techniques.\n",
    "This example uses a linear SVM (LIBLINEAR.jl).\n",
    "\n",
    "## Example\n",
    "\n",
    "\n",
    "The first step is to initialize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mActivating\u001b[22m\u001b[39m environment at `~/Research/TextSearch.jl/examples/Project.toml`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "using Pkg\n",
    "pkg\"activate .\"\n",
    "# uncomment to install the required packages\n",
    "## pkg\"add https://github.com/sadit/SimilaritySearch.jl https://github.com/sadit/TextSearch.jl https://github.com/sadit/KernelMethods.jl LIBLINEAR Random StatsBase\"\n",
    "using SimilaritySearch, TextSearch, LIBLINEAR, Random, StatsBase, KernelMethods\n",
    "\n",
    "\n",
    "# fetching data\n",
    "url = \"http://ingeotec.mx/~sadit/emospace50k.json.gz\"\n",
    "!isfile(basename(url)) && download(url, basename(url))\n",
    "db = loadtweets(basename(url))\n",
    "n = length(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning the data\n",
    "\n",
    "To estimate the performance of our predictions, we divide our dataset in a 50-50 partition for training and testing collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fitting VectorModel with 25000 items\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxfinished VectorModel: 25000 processed items, voc-size: 229379\n"
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching isless(::TextSearch.IdFreq, ::Int64)\nClosest candidates are:\n  isless(!Matched::Missing, ::Any) at missing.jl:66\n  isless(!Matched::AbstractFloat, ::Real) at operators.jl:158\n  isless(!Matched::Real, ::Real) at operators.jl:346\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching isless(::TextSearch.IdFreq, ::Int64)\nClosest candidates are:\n  isless(!Matched::Missing, ::Any) at missing.jl:66\n  isless(!Matched::AbstractFloat, ::Real) at operators.jl:158\n  isless(!Matched::Real, ::Real) at operators.jl:346\n  ...",
      "",
      "Stacktrace:",
      " [1] max(::Int64, ::TextSearch.IdFreq) at ./operators.jl:408",
      " [2] prune_select_top(::VectorModel, ::Int64, ::Type{IdfModel}) at /Users/sadit/.julia/packages/TextSearch/z5AQS/src/basicmodels.jl:104",
      " [3] prune_select_top at /Users/sadit/.julia/packages/TextSearch/z5AQS/src/basicmodels.jl:121 [inlined] (repeats 2 times)",
      " [4] main_tfidf(::Array{Dict,1}) at ./In[4]:28",
      " [5] top-level scope at show.jl:576",
      " [6] top-level scope at In[4]:40"
     ]
    }
   ],
   "source": [
    "\n",
    "function entropy_vectors(corpus, labels)\n",
    "    le = fit(LabelEncoder, labels)\n",
    "    model = fit(EntModel, config, corpus[P1], KernelMethods.transform.(le, labels[P1]),smooth=9)\n",
    "    model = prune_select_top(model, 0.2)\n",
    "    @info \"number-of-tokens:\" length(model.tokens)\n",
    "\n",
    "    X = [vectorize(model, EntModel, text) for text in corpus]\n",
    "    X[P1], X[P2], labels[P1], labels[P2]\n",
    "end\n",
    "\n",
    "\n",
    "function main_tfidf(db)\n",
    "    G = shuffle(1:n)\n",
    "    P1 = G[1:div(length(G), 2)]\n",
    "    P2 = G[div(length(G), 2)+1:end]\n",
    "\n",
    "    corpus = get.(db, \"text\", \"\")\n",
    "    labels = get.(db, \"klass\", \"\")\n",
    "    corpus_train, labels_train = corpus[P1], labels[P1]\n",
    "    corpus_test, labels_test = corpus[P2], labels[P2]\n",
    "    \n",
    "    # TextConfig specifies the way the text will be processed;\n",
    "    # note that emoticons are specially handled to remove them from the text\n",
    "    config = TextConfig(qlist=[3, 5], nlist=[], group_emo=true)\n",
    "    model_ = fit(VectorModel, config, corpus_train)\n",
    "    for p in [1.0, 0.9, 0.7, 0.5, 0.3, 0.1]\n",
    "        model = prune_select_top(model_, p)\n",
    "        Xtrain = [vectorize(model, TfidfModel, text) for text in corpus_train]\n",
    "        Xtest = [vectorize(model, TfidfModel, text) for text in corpus_test]\n",
    "\n",
    "        #Xtrain, Xtest, ytrain, ytest = entropy_vectors(corpus, labels)\n",
    "        # Xtrain, Xtest, ytrain, ytest = tfidf_vectors(corpus, labels)\n",
    "        classifier = linear_train(labels[P1], hcat(Xtrain...), C=0.1)\n",
    "        predictions, decision_values = linear_predict(classifier, hcat(Xtest...))\n",
    "        accuracy = mean(labels_test .== predictions)\n",
    "        display(p => accuracy)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "@show main_tfidf(db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
